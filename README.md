# Vanta Chat UI

Simple and lightweight chat for Ollama local models.

## Project Goals

- A simple and lightweight chat UI for Ollama local models.
- Provide a clean and intuitive interface for interacting with local LLMs.
- Easy to set up and use.

## Features

- Chat with local Ollama models.
- Select from a list of available Ollama models.
- Chat history with the ability to rename and delete chats.
- Collapsible "thinking" block to show the model's thought process.
- Responsive design with a collapsible sidebar.
- Dark theme.

## Future Plans

- Support for more LLM providers (e.g., OpenAI, Anthropic).
- Light theme.
- Improved UI/UX.
- More customization options.
- File attachments.

## Running Guides

### Prerequisites

- Node.js and pnpm
- Ollama installed and running.

### Installation

1. Clone the repository.
2. Install dependencies:

```bash
pnpm install
```

### Running the app

1. Run the development server:

```bash
pnpm dev
```

2. Open [http://localhost:3000](http://localhost:3000) in your browser.